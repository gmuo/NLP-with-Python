{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNR - Práctica 3\n",
    "## Sesión 3: Validación de Clasificadores\n",
    "\n",
    "Nombre:\n",
    "- Guillermo Ferrando Muñoz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar los parámetros del clasificador propuesto para la tarea DETESTS empleando la\n",
    "medida de evaluación F1, y empleando un esquema de validación cruzada. Entregar código\n",
    "e informe con la explicación de la estrategia utilizada antes de la siguiente sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos con el desbalanceo solucionado mediante SMOTE oversampling que obtuvimos en la sesión anterior de esta práctica. Para ello, leemos el documento \"S3_P3.csv\" que he generado, lo incluiré en la entrega de la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>stereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.005706</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-0.003248</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001581</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>-0.001341</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>-0.002786</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.004574</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.007377</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.006015</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>-0.006664</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>-0.009904</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>-0.005930</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000654</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>-0.004364</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>-0.008393</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.001318  0.003393  0.002340 -0.002296  0.004027  0.002442  0.000703   \n",
       "1  0.001163  0.002280  0.005396 -0.005706  0.003198  0.001721  0.002030   \n",
       "2 -0.001684  0.003351 -0.000300  0.000164  0.000150 -0.003695  0.001025   \n",
       "3  0.001581 -0.000432  0.002926 -0.001243  0.000831 -0.002557  0.003618   \n",
       "4 -0.000496 -0.000016  0.007480 -0.002841 -0.001257 -0.001341  0.001828   \n",
       "5  0.000717  0.001005 -0.000263  0.000679  0.001691 -0.003206 -0.002786   \n",
       "6 -0.004574 -0.001306  0.000020 -0.002135 -0.000803  0.000261 -0.000666   \n",
       "7 -0.007377  0.000183  0.004989 -0.006015  0.002102 -0.002705 -0.006664   \n",
       "8 -0.000654  0.001425  0.000660  0.001815 -0.002990 -0.001975  0.000159   \n",
       "9  0.004029  0.002029  0.004909 -0.000626  0.000693 -0.003865  0.001327   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  0.001406 -0.002482  0.000745  ... -0.001195 -0.000311 -0.000729  0.001500   \n",
       "1  0.004187 -0.003248  0.007304  ... -0.002858  0.007483 -0.001480  0.005370   \n",
       "2  0.005774  0.001311 -0.000973  ...  0.000300  0.000582 -0.004117  0.001826   \n",
       "3  0.003611  0.000520 -0.000479  ...  0.001939 -0.002411 -0.002368  0.001319   \n",
       "4  0.003550  0.003153  0.001166  ...  0.000466  0.005146  0.002355  0.002462   \n",
       "5  0.006954 -0.001253  0.001588  ...  0.000191 -0.002558 -0.002527  0.007731   \n",
       "6  0.002697  0.000333  0.002623  ... -0.002448  0.001542  0.000938  0.005675   \n",
       "7  0.009896 -0.009904  0.007932  ...  0.008981  0.001597  0.000005 -0.006048   \n",
       "8  0.004599 -0.004364  0.000639  ... -0.003120  0.004801 -0.000113  0.003341   \n",
       "9 -0.008393 -0.000097 -0.005665  ...  0.001387  0.005404 -0.005205  0.001415   \n",
       "\n",
       "         95        96        97        98        99  stereotype  \n",
       "0 -0.000136 -0.002057  0.004157  0.002924  0.003697           0  \n",
       "1 -0.002683  0.005325 -0.001532  0.000768 -0.002241           0  \n",
       "2  0.002370  0.000677 -0.001318 -0.000238  0.002707           0  \n",
       "3 -0.000663  0.004117 -0.000327  0.003946  0.004706           0  \n",
       "4  0.003463  0.002679  0.001108 -0.001922  0.000507           0  \n",
       "5  0.003119 -0.003920  0.001947 -0.004730 -0.002866           0  \n",
       "6 -0.000728  0.002071 -0.001132  0.002149 -0.001617           0  \n",
       "7  0.009836  0.006450 -0.005930  0.005494  0.005669           0  \n",
       "8  0.002509  0.002654  0.000550  0.001538  0.003378           0  \n",
       "9  0.006878  0.000329 -0.003058 -0.003888  0.002836           0  \n",
       "\n",
       "[10 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"S3_P3.csv\")\n",
    "df=df.drop(columns=['Unnamed: 0']) #para eliminar una columna inútil\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"stereotype\", axis=1).values\n",
    "y = df[\"stereotype\"].values\n",
    "#X_train, y_train = shuffle(X_train, y_train) #para barajar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrategias de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ir implemetando las distintas estrategias de validación de modelos que se indican en el boletín de la práctica. Comenzamos partiendo los datos en para el entrenamiento y la prueba. El 25% de los datos será la parte de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                          test_size=0.25, shuffle = True, random_state=42) #shuffle = True para barajar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de SVM mediante Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer método es **Holdout**, como decíamos antes, la parte de test el el 25%, que está entre en 1/3% y el 1/2% que se menciona en la explicación del boletín. El modelo a utilizar será **SVM**, ya que vimos en la anterior sesión que daba los mejores resultados, y para validar, haremos una única iteración y evaluaremos con la medida F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.         0.66273264]\n",
      "macro F1 0.33136631865637767\n",
      "micro F1 0.4955872369314325\n",
      "\n",
      "Métricas con validación cruzada: \n",
      "macro F1 [0.33433735 0.33383572 0.33383572 0.33383572 0.33408748]\n",
      "micro F1 [0.50226244 0.50113122 0.50113122 0.50113122 0.50169875]\n",
      "\n",
      "Ha tardado 14.39 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                #This does not take label imbalance into account.\n",
    "print(\"macro F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                #false negatives and false positives.\n",
    "print(\"micro F1\", a)\n",
    "\n",
    "print()\n",
    "print('Métricas con validación cruzada: ')\n",
    "\n",
    "macro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"macro F1\", macro)\n",
    "\n",
    "micro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "print(\"micro F1\", micro)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que los resultados se obtienen muy rápido, pero no son buenos, ya que el kernel utilizado es lineal y el parámetro `C=1` no daba buenos resultados, según vimos en la anterior sesión. Por ello, vamos a aplicar **GridSearchCV** para intentar encontrar los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo óptimo SVM según GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar con todos los kernels posibles que ofrece la función, seguramente tardará mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'rbf'}\n",
      "SVC(C=10)\n",
      "\n",
      "Ha tardado 212.64 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid={'C': [2,3,4,5,10],\n",
    "                                                    'kernel': ('linear', 'rbf', 'poly', 'sigmoid')})\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Obtener los mejores hiper-parámetros\n",
    "print(clf.best_params_)\n",
    "#Obtener el mejor clasificador\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No ha tardado tanto al final. El mejor modelo es el que lleva `kernel = 'rbf'` y `C=10`. Ese valor de C es un poco sospechoso, en el sentido de que puede estar provocando un sobreajuste, pero lo probaremos igual. A continuación, ajustamos este modelo y vemos su evaluación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo óptimo de SVM según GrindSearchCV validado mediante Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.88477952 0.89480519]\n",
      "macro F1 0.8897923555818293\n",
      "micro F1 0.890020366598778\n",
      "\n",
      "Métricas con validación cruzada: \n",
      "macro F1 [0.87292852 0.85837528 0.88996044 0.84544183 0.85893987]\n",
      "micro F1 [0.87330317 0.85859729 0.89027149 0.84615385 0.85956965]\n",
      "Accuracy: 0.890020366598778\n",
      "\n",
      "Ha tardado 18.08 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=10, random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                #This does not take label imbalance into account.\n",
    "print(\"macro F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                #false negatives and false positives.\n",
    "print(\"micro F1\", a)\n",
    "\n",
    "print()\n",
    "print('Métricas con validación cruzada: ')\n",
    "\n",
    "macro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"macro F1\", macro)\n",
    "\n",
    "micro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "print(\"micro F1\", micro)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En efecto, conseguimos unos buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo óptimo de regresión logística según RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ver también resultados de RandomizedSearchCV, probaremos la regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.7839693033701929, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.7839693033701929)\n",
      "\n",
      "Ha tardado 1.25 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.5953862         nan 0.59244375        nan        nan        nan\n",
      "        nan 0.60850863        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tini = time.process_time()\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.5472561  0.63647491]\n",
      "macro F1 0.591865502880855\n",
      "micro F1 0.5967413441955194\n",
      "\n",
      "Métricas con validación cruzada: \n",
      "macro F1 [0.59884488 0.61521295 0.57724463 0.60636132 0.59602528]\n",
      "micro F1 [0.60180995 0.62556561 0.58710407 0.6199095  0.60815402]\n",
      "\n",
      "Ha tardado 0.75 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "clf = LogisticRegression(C = 0.7839693033701929, penalty = 'l2').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                #This does not take label imbalance into account.\n",
    "print(\"macro F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                #false negatives and false positives.\n",
    "print(\"micro F1\", a)\n",
    "\n",
    "print()\n",
    "print('Métricas con validación cruzada: ')\n",
    "\n",
    "macro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"macro F1\", macro)\n",
    "\n",
    "micro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "print(\"micro F1\", micro)\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son iguales a lo que sacamos en la anterior sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo óptimo de regresión logística según RandomizedSearchCV validado mediante Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.5472561  0.63647491]\n",
      "macro F1 0.591865502880855\n",
      "micro F1 0.5967413441955194\n",
      "\n",
      "Métricas con validación cruzada: \n",
      "macro F1 [0.59884488 0.61521295 0.57724463 0.60636132 0.59602528]\n",
      "micro F1 [0.60180995 0.62556561 0.58710407 0.6199095  0.60815402]\n",
      "\n",
      "Ha tardado 0.47 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "logistic = LogisticRegression(C=0.7839693033701929, penalty = 'l2').fit(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                #This does not take label imbalance into account.\n",
    "print(\"macro F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                #false negatives and false positives.\n",
    "print(\"micro F1\", a)\n",
    "\n",
    "print()\n",
    "print('Métricas con validación cruzada: ')\n",
    "\n",
    "macro = cross_val_score(logistic, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"macro F1\", macro)\n",
    "\n",
    "micro = cross_val_score(logistic, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "print(\"micro F1\", micro)\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy rápido, pero con resultados notablemente peores a la máquina de soporte vectorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-baa3112fb967>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'solver'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_iter'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1700\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2000\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpha'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m10.0\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hidden_layer_sizes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'random_state'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold con el modelo SVM óptimo anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seguir la misma estructura que hemos llevado en Holdout, pero validando ahora el modelo óptimo SVM de antes con validación cruzada: **K-fold**. Vamos a hacer un bucle con distintos valores de k.\n",
    "\n",
    "**Nota**: No aplicaremos el método Leave one-out porque tenemos 5892 observaciones, lo que significaría ajustar 5892 modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "F1 promedio 0.8592180928412723\n",
      "macro F1 promedio 0.8513284521556909\n",
      "micro F1 promedio 0.8517764200045259\n",
      "\n",
      "K = 4\n",
      "F1 promedio 0.864896356257197\n",
      "macro F1 promedio 0.8569168593221425\n",
      "micro F1 promedio 0.857432659518657\n",
      "\n",
      "K = 5\n",
      "F1 promedio 0.8728889909618672\n",
      "macro F1 promedio 0.8655765420297232\n",
      "micro F1 promedio 0.8660318330660081\n",
      "\n",
      "K = 6\n",
      "F1 promedio 0.8756994031635278\n",
      "macro F1 promedio 0.8680161061462147\n",
      "micro F1 promedio 0.8685177742709378\n",
      "\n",
      "K = 7\n",
      "F1 promedio 0.8791617304648592\n",
      "macro F1 promedio 0.8718311145323209\n",
      "micro F1 promedio 0.8723717054074734\n",
      "\n",
      "K = 8\n",
      "F1 promedio 0.8777240171134087\n",
      "macro F1 promedio 0.8702411378016688\n",
      "micro F1 promedio 0.8707871425950676\n",
      "\n",
      "K = 9\n",
      "F1 promedio 0.8740722717933121\n",
      "macro F1 promedio 0.8666036979320474\n",
      "micro F1 promedio 0.867164516859018\n",
      "\n",
      "K = 10\n",
      "F1 promedio 0.8798470596839125\n",
      "macro F1 promedio 0.8732499091013217\n",
      "micro F1 promedio 0.8737238485137645\n",
      "\n",
      "\n",
      "Ha tardado 79.92 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "for i in range(3,11):\n",
    "    kf = KFold(n_splits=i)\n",
    "    print('K =',i)    \n",
    "    f=[]\n",
    "    mac=[]\n",
    "    mic=[]\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_i, X_test_i, y_train_i, y_test_i = X_train[train], X_train[test], y_train[train], y_train[test]\n",
    "\n",
    "        clf = svm.SVC(kernel='rbf', C=10, random_state=42).fit(X_train_i, y_train_i)\n",
    "        y_pred_i = clf.predict(X_test_i)\n",
    "        \n",
    "        f1=f1_score(y_test_i, y_pred_i, zero_division=1)\n",
    "        f.append(f1)\n",
    "\n",
    "        macro=f1_score(y_test_i, y_pred_i, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                        #This does not take label imbalance into account.\n",
    "        mac.append(macro)\n",
    "\n",
    "        micro=f1_score(y_test_i, y_pred_i, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                        #false negatives and false positives.\n",
    "        mic.append(micro)\n",
    "    print(\"F1 promedio\", sum(f)/i)\n",
    "    print(\"macro F1 promedio\", sum(mac)/i)\n",
    "    print(\"micro F1 promedio\", sum(mic)/i)\n",
    "    print()\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de cada fold casi no varían. A partir de K=5 parece que se queda en una pequeña mejora, pero, de nuevo, casi insignificante. Por tanto, podemos reafirmar que el modelo óptimo según GrindSearchCV es bueno, ya que no es sensible a diferentes muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-fold con el modelo SVM óptimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplemente por probar lo mostrado en el boletín de la práctica, vamos a aplicar Stratified K-fold con nuestro modelo de SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "F1 promedio 0.8595567502422353\n",
      "macro F1 promedio 0.8520630507936539\n",
      "micro F1 promedio 0.8524553066304593\n",
      "\n",
      "K = 4\n",
      "F1 promedio 0.8650489487636854\n",
      "macro F1 promedio 0.8567057203293226\n",
      "micro F1 promedio 0.8572064151747656\n",
      "\n",
      "K = 5\n",
      "F1 promedio 0.8727838511540004\n",
      "macro F1 promedio 0.8651291861998027\n",
      "micro F1 promedio 0.8655790881558652\n",
      "\n",
      "K = 6\n",
      "F1 promedio 0.8754381589566088\n",
      "macro F1 promedio 0.8675718979195913\n",
      "micro F1 promedio 0.8680657974947397\n",
      "\n",
      "K = 7\n",
      "F1 promedio 0.880317426174198\n",
      "macro F1 promedio 0.8725487491560031\n",
      "micro F1 promedio 0.873049824756479\n",
      "\n",
      "K = 8\n",
      "F1 promedio 0.8769384612138575\n",
      "macro F1 promedio 0.8694077316731261\n",
      "micro F1 promedio 0.8698821644783394\n",
      "\n",
      "K = 9\n",
      "F1 promedio 0.8768726478231097\n",
      "macro F1 promedio 0.8696857758430473\n",
      "micro F1 promedio 0.8701063589047298\n",
      "\n",
      "K = 10\n",
      "F1 promedio 0.8811554020228973\n",
      "macro F1 promedio 0.8742105847283919\n",
      "micro F1 promedio 0.8746267737864377\n",
      "\n",
      "\n",
      "Ha tardado 87.12 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "for i in range(3,11):\n",
    "    kf = StratifiedKFold(n_splits=i)\n",
    "    print('K =',i)    \n",
    "    f=[]\n",
    "    mac=[]\n",
    "    mic=[]\n",
    "    #Para hacer las particiones es necesario usar la variable con las clases (y_train)\n",
    "    for train, test in kf.split(X_train,y_train):\n",
    "        X_train_i, X_test_i, y_train_i, y_test_i = X_train[train], X_train[test], y_train[train], y_train[test]\n",
    "\n",
    "        clf = svm.SVC(kernel='rbf', C=10, random_state=42).fit(X_train_i, y_train_i)\n",
    "        y_pred_i = clf.predict(X_test_i)\n",
    "        \n",
    "        f1=f1_score(y_test_i, y_pred_i, zero_division=1)\n",
    "        f.append(f1)\n",
    "\n",
    "        macro=f1_score(y_test_i, y_pred_i, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                        #This does not take label imbalance into account.\n",
    "        mac.append(macro)\n",
    "\n",
    "        micro=f1_score(y_test_i, y_pred_i, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                        #false negatives and false positives.\n",
    "        mic.append(micro)\n",
    "    print(\"F1 promedio\", sum(f)/i)\n",
    "    print(\"macro F1 promedio\", sum(mac)/i)\n",
    "    print(\"micro F1 promedio\", sum(mic)/i)\n",
    "    print()\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados similares a los de K-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repetir todo (lo más importante) con árboles de decisión, que era el segundo modelo con mejor puntuación de lo que probé en la anterior sesión de esta práctica. A ver si vemos alguna mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo óptimo obtenido con GrindSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores a probar del argumento max_depth son aleatorios. Lo mejor sería sacar una lista con valores de uno en uno, pero tardaría demasiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 30}\n",
      "DecisionTreeClassifier(max_depth=30)\n",
      "\n",
      "Ha tardado 195.47 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.73257468 0.75584416]\n",
      "0.7558441558441559\n",
      "0.7442094178936284\n",
      "0.7447386286490155\n",
      "Accuracy: 0.7447386286490156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion = 'gini', max_depth=30).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "f1=f1_score(y_test, y_pred, zero_division=1)\n",
    "print(f1)\n",
    "\n",
    "macro=f1_score(y_test, y_pred, average='macro')\n",
    "print(macro)\n",
    "\n",
    "micro=f1_score(y_test, y_pred, average='micro')\n",
    "print(micro)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación con K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "F1 promedio 0.7322523633286195\n",
      "macro F1 promedio 0.7231317515872545\n",
      "micro F1 promedio 0.7234668477031003\n",
      "\n",
      "K = 4\n",
      "F1 promedio 0.7406224217171944\n",
      "macro F1 promedio 0.7279967890372572\n",
      "micro F1 promedio 0.7286678634664568\n",
      "\n",
      "K = 5\n",
      "F1 promedio 0.7283298888464206\n",
      "macro F1 promedio 0.7197437270910065\n",
      "micro F1 promedio 0.720299472694383\n",
      "\n",
      "K = 6\n",
      "F1 promedio 0.7375698017569682\n",
      "macro F1 promedio 0.7260656327938594\n",
      "micro F1 promedio 0.7266320939767565\n",
      "\n",
      "K = 7\n",
      "F1 promedio 0.7375583286252215\n",
      "macro F1 promedio 0.7253275245965852\n",
      "micro F1 promedio 0.7261823564307065\n",
      "\n",
      "K = 8\n",
      "F1 promedio 0.7362605760133003\n",
      "macro F1 promedio 0.7254447824353656\n",
      "micro F1 promedio 0.7259587035144273\n",
      "\n",
      "K = 9\n",
      "F1 promedio 0.7337889172532734\n",
      "macro F1 promedio 0.7211703789929348\n",
      "micro F1 promedio 0.7221090744512334\n",
      "\n",
      "K = 10\n",
      "F1 promedio 0.741218776130362\n",
      "macro F1 promedio 0.7328272487802739\n",
      "micro F1 promedio 0.7334190086290927\n",
      "\n",
      "\n",
      "Ha tardado 70.86 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "for i in range(3,11):\n",
    "    kf = KFold(n_splits=i)\n",
    "    print('K =',i)    \n",
    "    f=[]\n",
    "    mac=[]\n",
    "    mic=[]\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_i, X_test_i, y_train_i, y_test_i = X_train[train], X_train[test], y_train[train], y_train[test]\n",
    "\n",
    "        clf = DecisionTreeClassifier(criterion = 'gini', max_depth=30).fit(X_train_i, y_train_i)\n",
    "        y_pred_i = clf.predict(X_test_i)\n",
    "        \n",
    "        f1=f1_score(y_test_i, y_pred_i, zero_division=1)\n",
    "        f.append(f1)\n",
    "\n",
    "        macro=f1_score(y_test_i, y_pred_i, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                        #This does not take label imbalance into account.\n",
    "        mac.append(macro)\n",
    "\n",
    "        micro=f1_score(y_test_i, y_pred_i, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                        #false negatives and false positives.\n",
    "        mic.append(micro)\n",
    "    print(\"F1 promedio\", sum(f)/i)\n",
    "    print(\"macro F1 promedio\", sum(mac)/i)\n",
    "    print(\"micro F1 promedio\", sum(mic)/i)\n",
    "    print()\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo el valor de K no afecta a la puntuación. Estas puntuaciones son casi iguales a las de la anterior sesión, que daban 0.71, pero al menos hay un poco de mejora. Por último, vamos a ver qué sacamos con Stratified K-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación con Stratified K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "F1 promedio 0.7372196254686901\n",
      "macro F1 promedio 0.7241547931605288\n",
      "micro F1 promedio 0.724824620954967\n",
      "\n",
      "K = 4\n",
      "F1 promedio 0.7400164599601524\n",
      "macro F1 promedio 0.7281211114124765\n",
      "micro F1 promedio 0.7286688881238115\n",
      "\n",
      "K = 5\n",
      "F1 promedio 0.7392397739704394\n",
      "macro F1 promedio 0.7262178521962313\n",
      "micro F1 promedio 0.7268603024448738\n",
      "\n",
      "K = 6\n",
      "F1 promedio 0.7426056285596392\n",
      "macro F1 promedio 0.7320254639060538\n",
      "micro F1 promedio 0.7325154735217195\n",
      "\n",
      "K = 7\n",
      "F1 promedio 0.7328349071734294\n",
      "macro F1 promedio 0.7186289147113973\n",
      "micro F1 promedio 0.7193868339528233\n",
      "\n",
      "K = 8\n",
      "F1 promedio 0.7415215441834929\n",
      "macro F1 promedio 0.7304388287713256\n",
      "micro F1 promedio 0.730932397725188\n",
      "\n",
      "K = 9\n",
      "F1 promedio 0.7449113880979565\n",
      "macro F1 promedio 0.7333095133459523\n",
      "micro F1 promedio 0.7338764426340801\n",
      "\n",
      "K = 10\n",
      "F1 promedio 0.7485861140709582\n",
      "macro F1 promedio 0.7388610133996587\n",
      "micro F1 promedio 0.7393039266988847\n",
      "\n",
      "\n",
      "Ha tardado 68.53 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "for i in range(3,11):\n",
    "    kf = StratifiedKFold(n_splits=i)\n",
    "    print('K =',i)    \n",
    "    f=[]\n",
    "    mac=[]\n",
    "    mic=[]\n",
    "    #Para hacer las particiones es necesario usar la variable con las clases (y_train)\n",
    "    for train, test in kf.split(X_train,y_train):\n",
    "        X_train_i, X_test_i, y_train_i, y_test_i = X_train[train], X_train[test], y_train[train], y_train[test]\n",
    "\n",
    "        clf = DecisionTreeClassifier(criterion = 'gini', max_depth=30).fit(X_train_i, y_train_i)\n",
    "        y_pred_i = clf.predict(X_test_i)\n",
    "        \n",
    "        f1=f1_score(y_test_i, y_pred_i, zero_division=1)\n",
    "        f.append(f1)\n",
    "\n",
    "        macro=f1_score(y_test_i, y_pred_i, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                        #This does not take label imbalance into account.\n",
    "        mac.append(macro)\n",
    "\n",
    "        micro=f1_score(y_test_i, y_pred_i, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                        #false negatives and false positives.\n",
    "        mic.append(micro)\n",
    "    print(\"F1 promedio\", sum(f)/i)\n",
    "    print(\"macro F1 promedio\", sum(mac)/i)\n",
    "    print(\"micro F1 promedio\", sum(mic)/i)\n",
    "    print()\n",
    "\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados se ven incluso menos afectados por las diferentes muestras, llegando a mejorarse un poco más incluso las métricas (muy poco, alrededor de 1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breves conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GrindSearchCV ha sido un buen descubrimiento que usaré en el futuro, me habría gustado saberlo desde antes. El *ranking* de los modelos se mantiene igual que en la sesión anterior de esta práctica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
