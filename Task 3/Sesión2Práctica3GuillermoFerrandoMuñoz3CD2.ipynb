{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNR - Práctica 3\n",
    "## Sesión 2: Clasificación automática\n",
    "\n",
    "Nombre:\n",
    "- Guillermo Ferrando Muñoz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar un clasificador para los datos de la tarea de detección de estereotipos\n",
    "en DETESTS. Es importante que se entren al menos dos clasificadores\n",
    "diferentes y se comparen sus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar cargando los datos de DETESTS modificados con los resultados obtenidos en la anterior práctica de esta sesión, es decir, la columna \"sentence\" inicial es sustituida por los vectores de 100 componentes del word embedding y se le añade la columna de \"stereotype\", que será la variable respuesta. Estos datos los cargo directamente del fichero \"S2_P3.csv\" que he generado, lo incluiré en la entrega de la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>stereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.005706</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-0.003248</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001581</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>-0.001341</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>-0.003206</td>\n",
       "      <td>-0.002786</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.004574</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.007377</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.006015</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>-0.006664</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>-0.009904</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>-0.005930</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000654</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>-0.004364</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>-0.008393</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.001318  0.003393  0.002340 -0.002296  0.004027  0.002442  0.000703   \n",
       "1  0.001163  0.002280  0.005396 -0.005706  0.003198  0.001721  0.002030   \n",
       "2 -0.001684  0.003351 -0.000300  0.000164  0.000150 -0.003695  0.001025   \n",
       "3  0.001581 -0.000432  0.002926 -0.001243  0.000831 -0.002557  0.003618   \n",
       "4 -0.000496 -0.000016  0.007480 -0.002841 -0.001257 -0.001341  0.001828   \n",
       "5  0.000717  0.001005 -0.000263  0.000679  0.001691 -0.003206 -0.002786   \n",
       "6 -0.004574 -0.001306  0.000020 -0.002135 -0.000803  0.000261 -0.000666   \n",
       "7 -0.007377  0.000183  0.004989 -0.006015  0.002102 -0.002705 -0.006664   \n",
       "8 -0.000654  0.001425  0.000660  0.001815 -0.002990 -0.001975  0.000159   \n",
       "9  0.004029  0.002029  0.004909 -0.000626  0.000693 -0.003865  0.001327   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  0.001406 -0.002482  0.000745  ... -0.001195 -0.000311 -0.000729  0.001500   \n",
       "1  0.004187 -0.003248  0.007304  ... -0.002858  0.007483 -0.001480  0.005370   \n",
       "2  0.005774  0.001311 -0.000973  ...  0.000300  0.000582 -0.004117  0.001826   \n",
       "3  0.003611  0.000520 -0.000479  ...  0.001939 -0.002411 -0.002368  0.001319   \n",
       "4  0.003550  0.003153  0.001166  ...  0.000466  0.005146  0.002355  0.002462   \n",
       "5  0.006954 -0.001253  0.001588  ...  0.000191 -0.002558 -0.002527  0.007731   \n",
       "6  0.002697  0.000333  0.002623  ... -0.002448  0.001542  0.000938  0.005675   \n",
       "7  0.009896 -0.009904  0.007932  ...  0.008981  0.001597  0.000005 -0.006048   \n",
       "8  0.004599 -0.004364  0.000639  ... -0.003120  0.004801 -0.000113  0.003341   \n",
       "9 -0.008393 -0.000097 -0.005665  ...  0.001387  0.005404 -0.005205  0.001415   \n",
       "\n",
       "         95        96        97        98        99  stereotype  \n",
       "0 -0.000136 -0.002057  0.004157  0.002924  0.003697           0  \n",
       "1 -0.002683  0.005325 -0.001532  0.000768 -0.002241           0  \n",
       "2  0.002370  0.000677 -0.001318 -0.000238  0.002707           0  \n",
       "3 -0.000663  0.004117 -0.000327  0.003946  0.004706           0  \n",
       "4  0.003463  0.002679  0.001108 -0.001922  0.000507           0  \n",
       "5  0.003119 -0.003920  0.001947 -0.004730 -0.002866           0  \n",
       "6 -0.000728  0.002071 -0.001132  0.002149 -0.001617           0  \n",
       "7  0.009836  0.006450 -0.005930  0.005494  0.005669           0  \n",
       "8  0.002509  0.002654  0.000550  0.001538  0.003378           0  \n",
       "9  0.006878  0.000329 -0.003058 -0.003888  0.002836           0  \n",
       "\n",
       "[10 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"S2_P3.csv\")\n",
    "df=df.drop(columns=['Unnamed: 0']) #para eliminar una columna inútil\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Desbalance de stereotype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos cargados, vamos a consultar si \"stereotype\" (clase binaria) está desbalanceada. A simple vista, parece que la mayoría de las oraciones son de la clase 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores que toma la variable stereotype: \n",
      "[0 1]\n",
      "\n",
      "Conteo de clases de stereotype: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2946\n",
       "1     871\n",
       "Name: stereotype, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Valores que toma la variable stereotype: \")\n",
    "print(df[\"stereotype\"].unique()) # es binaria\n",
    "print()\n",
    "print(\"Conteo de clases de stereotype: \")\n",
    "df[\"stereotype\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 77% de los datos pertenecen a la clase 0 y el 23% a la clase 1, por tanto, **en efecto tenemos un desbalance**. Lo tendremos en cuenta a la hora de implementar los clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos SMOTE para balancear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con SMOTE oversampling creamos nuevas observaciones sintéticas de la clase minoritaria, en este caso la clase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos los datos en conjunto `X` y conjunto `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"stereotype\", axis=1).values\n",
    "y = df[\"stereotype\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "XSMOTE, ySMOTE = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2946, 1: 2946})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ySMOTE) # ahora tenemos el mismo número de observaciones de la clase 0 y de la clase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(XSMOTE)\n",
    "jij = pd.DataFrame(ySMOTE)\n",
    "jij = jij.rename(columns={0:'stereotype'})\n",
    "s3_p3 = res.join(jij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_p3.to_csv(\"S3_P3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al haber hecho esto, los últimos valores de `y` serán todos de clase 1. Esto puede ser perjudicial si esa es la parte de test que obtenemos al dividir los datos, por lo que habrá que barajarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de modelos\n",
    "\n",
    "Abajo del todo añado unas breves conclusiones generales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de soporte vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer clasificador, usaremos SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8659209436235042\n",
      "\n",
      "Ha tardado 2.59 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(XSMOTE, ySMOTE, \n",
    "                                    test_size=0.25, shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = svm.SVC(kernel='rbf', gamma='scale', C=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con kenrel 'rbf' y el parámetro C=4, tenemos una puntuación de 0.87, es un buen resultado. Vamos a probar ahora qué resultado obtenemos con los datos sin balancear (sin hacer SMOTE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5501298867606974\n",
      "\n",
      "Ha tardado 1.38 segundos\n"
     ]
    }
   ],
   "source": [
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = svm.SVC(kernel='rbf', gamma='scale', C=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una considerable bajada en la puntuación, parece que el desbalanceo afecta mucho para SVM. Vamos a probar una vez más los datos desbalanceados, pero con un kernel diferente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.43922489724016445\n",
      "\n",
      "Ha tardado 0.39 segundos\n"
     ]
    }
   ],
   "source": [
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = svm.SVC(kernel = \"linear\", C = 4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un kernel lineal, los resultados empeoran más aún."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6057523755627248\n",
      "\n",
      "Ha tardado 0.11 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(XSMOTE, ySMOTE, \n",
    "                                    test_size=0.25, shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5642487923985414\n",
      "\n",
      "Ha tardado 0.02 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = LogisticRegression(class_weight= \"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.7184258643617021\n",
      "\n",
      "Ha tardado 1.02 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import tree\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(XSMOTE, ySMOTE, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5371050068186247\n",
      "\n",
      "Ha tardado 0.41 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import tree\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = tree.DecisionTreeClassifier(class_weight= \"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.61587811 0.71806945]\n",
      "macro F1 0.6669737800385434\n",
      "micro F1 0.6748133061778683\n",
      "Accuracy: 0.6748133061778683\n",
      "\n",
      "Métricas con validación cruzada: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0adade40b08c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Métricas con validación cruzada: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmacro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"macro F1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmacro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_test = train_test_split(XSMOTE, ySMOTE, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_eval)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average=None)\n",
    "print(\"F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='macro') #Calculate metrics for each label, and find their unweighted mean. \n",
    "                                                #This does not take label imbalance into account.\n",
    "print(\"macro F1\", a)\n",
    "\n",
    "a=f1_score(y_test, y_pred, average='micro') #Calculate metrics globally by counting the total true positives, \n",
    "                                                #false negatives and false positives.\n",
    "print(\"micro F1\", a)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))\n",
    "\n",
    "print()\n",
    "print('Métricas con validación cruzada: ')\n",
    "\n",
    "macro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"macro F1\", macro)\n",
    "\n",
    "micro = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "print(\"micro F1\", micro)\n",
    "\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.4666176558453198\n",
      "\n",
      "Ha tardado 16.86 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "tini = time.process_time()\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, \n",
    "                                                    shuffle = True, random_state=42) #shuffle = True para barajar los datos\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "score = f1_score(y_eval, pred, average='macro')\n",
    "\n",
    "print(\"Score: \",score)\n",
    "tfin = time.process_time()\n",
    "print()\n",
    "print(\"Ha tardado\", round(tfin-tini, 2), \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 4 tipos de métodos usados, los mejores resultados los han dado la máquina de soporte vectorial con kernel rbf y el árbol de decisión usando los datos generados con oversampling SMOTE, ambos con costes temporales similares. El desbalance afecta a todos los modelos casi en la misma magnitud; los resultados empeoran alrededor del 20% o más, lo que llama bastante a la atención."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
